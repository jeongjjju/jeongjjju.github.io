---
caption:
  title: Finger Language Translation Device
  subtitle: <strong>2022 Summer Annual Conference of IEIE</strong>
  category: 1Publications
  thumbnail: assets/img/portfolio/FingerLanguage_Translator/FingerTranslator.jpeg
  authors: Kim, J., <strong>Park, J.</strong>, Jeong, J., and Kim, D.
  prizes: üèÜ Outstanding Student Paper</br>üèÜ Capstone Design Industry-Academic Cooperation Competition

title: Design and Implementation of Bidirectinal Finger Language Translator Project
subtitle: 2022 Summer Annual Conference of IEIE
category: 1Publications
image: assets/img/portfolio/FingerLanguage_Translator/FingerTranslator.jpeg
alt: Keep Exploring
award: true
---
- Most farmers use sign language and Finger language as their first language.

- However, only a small number of people can speak sign language and Finger language in their daily lives, and the number of sign language interpreters who can translate them is also insufficient.

- To solve this problem, we design a device that translates Finger language into voice language and voice language into Finger language.

- The device consists of a voice translation mode and a Finger language translation mode, which are controlled through an application implemented in Unity.

- In the Finger language translation mode, landmark position is detected using mediapipe from a finger image obtained in real time through the device's camera, translated into the most similar Finger language using KNN, and output as a voice language through a speaker.

- In the voice translation mode, the voice language input through the microphone of the device is translated into paper in real time through the animation of the application and output.

- During the production process, there was no open source data related to Korean finger language, so 400 data were produced for 31 finger language operations.

- Out of a total of 12,600 data, learning was performed with 10000 data and 2,600 data were used to test the accuracy according to the k value, showing an average accuracy of 98%.

- Click [here](https://scholar.google.com/citations?view_op=view_citation&hl=ko&user=JmRPuDcAAAAJ&citation_for_view=JmRPuDcAAAAJ:u-x6o8ySG0sC) for more information about this project.